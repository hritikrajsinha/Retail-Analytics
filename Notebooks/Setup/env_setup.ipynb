{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "111af56d-3a52-4835-84e9-03990490df7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install pyyaml --upgrade\n",
    "import logging\n",
    "import os\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def safe_load_yaml(file_path):\n",
    "    try:\n",
    "        if not os.path.isfile(file_path):\n",
    "            logging.error(f\"Configuration file not found: {file_path}\")\n",
    "            raise FileNotFoundError (f\"Missing configuration file: {file_path}\")\n",
    "        else:\n",
    "            with open(file_path, 'r') as f:\n",
    "                return yaml.safe_load(f)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading YAML file: {e}\")\n",
    "\n",
    "def create_schema_if_not_exists(catalog, schema_name, spark):\n",
    "    spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {catalog}.{schema_name}\")\n",
    "\n",
    "def create_table_if_not_exists(catalog, schema_name, table_name, definition, spark):\n",
    "    cols=\", \".join([f\"{col['name']} {col['type']}\" for col in definition])\n",
    "    spark.sql(f\"CREATE TABLE IF NOT EXISTS {catalog}.{schema_name}.{table_name} ({cols})\")\n",
    "\n",
    "\n",
    "#creation of schemas and tables\n",
    "tbl_definitions=safe_load_yaml('/Workspace/Users/hritikraj143@gmail.com/Retail-Analytics/Config/table_definitions.yaml')\n",
    "glb_config=safe_load_yaml('/Workspace/Users/hritikraj143@gmail.com/Retail-Analytics/Config/global_config.yaml')\n",
    "catalog=glb_config['catalog']\n",
    "\n",
    "#validate yaml structure\n",
    "\n",
    "if not isinstance(tbl_definitions,dict):\n",
    "    raise ValueError('Invalid yaml format: Expected a dictionary')\n",
    "\n",
    "for schemas, tables in tbl_definitions.items():\n",
    "    if not isinstance(tables,dict):\n",
    "        logging.error(f\"Invalid yaml definition for schema {schemas}, expected a dictionary\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        create_schema_if_not_exists(catalog, schemas, spark)\n",
    "        logging.info(f\"Schema {schemas} created or already exists\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error creating schema {schemas}: {e}\")\n",
    "        continue\n",
    "\n",
    "    for table, meta in tables.items():\n",
    "        if not isinstance(meta,dict):\n",
    "            logging.error(f\"Invalid yaml definition for table {table},expected a dictionar\")\n",
    "            continue\n",
    "        try:\n",
    "            create_table_if_not_exists(catalog, schemas, table, meta['columns'], spark)\n",
    "            logging.info(f\"Table {table} created or already exists\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error creating table {table}: {e}\")\n",
    "            continue\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "env_setup",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
