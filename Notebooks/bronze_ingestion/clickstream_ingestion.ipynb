{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95b1d03d-be48-4e7f-b0da-321d44451f83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import current_timestamp\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s-%(name)s-%(levelname)s-%(message)s')\n",
    "\n",
    "def safe_load_yaml(file_path):\n",
    "    try:\n",
    "        if not os.path.isfile(file_path):\n",
    "            logging.error(f\"Configuration file not found: {file_path}\")\n",
    "            raise FileNotFoundError (f\"Missing configuration file: {file_path}\")\n",
    "        else:\n",
    "            with open(file_path, 'r') as f:\n",
    "                return yaml.safe_load(f)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading YAML file: {e}\")\n",
    "        raise\n",
    "\n",
    "def get_s3_data(file_path,file_format):\n",
    "    try:\n",
    "        if file_format=='csv':\n",
    "            return spark.read.format(file_format).load(file_path,header=True,inferschema=False)\n",
    "        else:\n",
    "            return spark.read.format(file_format).load(file_path)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error in reading the file from s3 at {file_path} : ,{e}\")\n",
    "\n",
    "\n",
    "#load yaml config\n",
    "global_config=safe_load_yaml('/Workspace/Users/hritikraj143@gmail.com/Retail-Analytics/Config/global_config.yaml')\n",
    "logging.info('global config loaded successfully')\n",
    "s3_clickstream_file_path=global_config['clickstream_file_path']\n",
    "if not isinstance(s3_clickstream_file_path, str):\n",
    "    raise ValueError('clickstream file path not found in config')\n",
    "catalog=global_config['catalog']\n",
    "if not isinstance(catalog, str):\n",
    "    raise ValueError('catalog not found in config')\n",
    "bronze_config=safe_load_yaml('/Workspace/Users/hritikraj143@gmail.com/Retail-Analytics/Config/bronze_config.yaml')\n",
    "logging.info('bronze config loaded successfully')\n",
    "target_schema=bronze_config['clickstream_landing']['target_schema']\n",
    "if not isinstance(target_schema, str):\n",
    "    raise ValueError('target_schema not found in config')\n",
    "target_table=bronze_config['clickstream_landing']['target_table']\n",
    "if not isinstance(target_table, str):\n",
    "    raise ValueError('target_table not found in config')\n",
    "clickstream_df=get_s3_data(s3_clickstream_file_path,'json')\n",
    "logging.info('clickstream.json from s3 is loaded successfully into the memory')\n",
    "clickstream_df = clickstream_df.withColumn(\"UpdatedAt\", current_timestamp())\n",
    "logging.info('clickstream.json from s3 is loaded successfully into the memory')\n",
    "clickstream_df = clickstream_df.withColumn(\"UpdatedAt\", current_timestamp())\n",
    "logging.info('UpdatedAt column added with current timestamp')\n",
    "clickstream_df.createOrReplaceTempView(\"clickstream_updates\")\n",
    "update_table_query=f\"\"\"MERGE INTO {catalog}.{target_schema}.{target_table} as trg\n",
    "using clickstream_updates as src\n",
    "ON trg.user_id = src.user_id\n",
    "AND trg.product_id=src.product_id\n",
    "WHEN MATCHED THEN\n",
    "UPDATE SET *\n",
    "WHEN NOT MATCHED THEN\n",
    "INSERT *\n",
    "\"\"\"\n",
    "try:\n",
    "    spark.sql(update_table_query)\n",
    "    logging.info(f\"query to update the {target_table} ran successfully\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"failed to run the query : {update_table_query}, {e}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "clickstream_ingestion",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
